#!/bin/bash

echo "ðŸ¤– WriteWise ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸"
echo "=================================="

# ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p models

# Python ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > download_models.py << 'EOF'
import os
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, TrOCRProcessor, VisionEncoderDecoderModel

def download_model(model_name, save_path, model_type="llm"):
    """ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜"""
    print(f"ðŸ“¥ {model_name} ë‹¤ìš´ë¡œë“œ ì¤‘...")
    
    try:
        if model_type == "llm":
            # LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
            tokenizer = AutoTokenizer.from_pretrained(model_name)
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                trust_remote_code=True
            )
            
            # íŒ¨ë”© í† í° ì„¤ì •
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
                
        elif model_type == "ocr":
            # OCR ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
            processor = TrOCRProcessor.from_pretrained(model_name)
            model = VisionEncoderDecoderModel.from_pretrained(model_name)
        
        # ëª¨ë¸ ì €ìž¥
        os.makedirs(save_path, exist_ok=True)
        tokenizer.save_pretrained(save_path)
        model.save_pretrained(save_path)
        
        print(f"âœ… {model_name} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {save_path}")
        return True
        
    except Exception as e:
        print(f"âŒ {model_name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    models = [
        {
            "name": "google/gemma-2b",
            "path": "./models/gemma-2b",
            "type": "llm"
        },
        {
            "name": "microsoft/trocr-base-handwritten",
            "path": "./models/trocr-handwritten",
            "type": "ocr"
        }
    ]
    
    print("ðŸš€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤...")
    print("âš ï¸  ì¸í„°ë„· ì—°ê²°ì´ ì•ˆì •ì ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”")
    print("âš ï¸  ë‹¤ìš´ë¡œë“œì—ëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ (ì´ ì•½ 3-4GB)")
    print()
    
    success_count = 0
    for model in models:
        if download_model(model["name"], model["path"], model["type"]):
            success_count += 1
        print()
    
    print(f"ðŸ“Š ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {success_count}/{len(models)} ëª¨ë¸")
    
    if success_count == len(models):
        print("ðŸŽ‰ ëª¨ë“  ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì´ì œ ./run_all.shë¡œ WriteWiseë¥¼ ì‹¤í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  ì¼ë¶€ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
EOF

# Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
echo "ðŸ Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘..."
python3 download_models.py

# ìž„ì‹œ íŒŒì¼ ì •ë¦¬
rm download_models.py

echo ""
echo "ðŸ“‹ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸:"
echo "- Gemma 2B: ./models/gemma-2b/"
echo "- TrOCR: ./models/trocr-handwritten/"
echo ""
echo "ðŸ’¡ ì´ì œ ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤." 